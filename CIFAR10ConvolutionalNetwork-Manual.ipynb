{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph() \n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pdb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to use the CIPHAR10 dataset from https://www.cs.toronto.edu/~kriz/cifar.html. Helpfully, the data is available in picked format which we can read with the following function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the first image. Originally this is a 3x1024 vector, representing all the colour channels. We want to display this with matplotlib, so we need to convert is to a 32x32x3 numpy array. In the mnist example, we were able to very easily extract batch of labels and images. We need to write our own way to extract batches of images. Since each chunk has size 10000, I'm going to extract out 100 batches per chunk, at a batch size of 100. We implement these in the following classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Chunk():\n",
    "    def __init__(self,chunk_filename):\n",
    "        self.chunk = self.unpickle(chunk_filename)\n",
    "        self.images = np.array([self.format_image(image) for image in self.chunk['data']])\n",
    "        self.labels = np.array([self.one_hot(label) for label in self.chunk['labels']])\n",
    "        self.idx = 0\n",
    "        \n",
    "    def one_hot(self,key):\n",
    "        vector = np.zeros(10, dtype=int)\n",
    "        vector[key] = int(1)\n",
    "        return vector\n",
    "                       \n",
    "        \n",
    "    def unpickle(self,chunk):\n",
    "        import cPickle\n",
    "        fo = open(chunk, 'rb')\n",
    "        dictionary = cPickle.load(fo)\n",
    "        fo.close()\n",
    "        return dictionary\n",
    "    def format_image(self,vector):\n",
    "        return vector.reshape(-1,32,32).transpose(1,2,0)\n",
    "    \n",
    "    def next_batch(self,number):\n",
    "        if self.idx < len(self.labels):\n",
    "            batch_images = self.images[self.idx : self.idx + number]\n",
    "            batch_labels = self.labels[self.idx : self.idx + number]\n",
    "            self.idx += number\n",
    "            return batch_images, batch_labels\n",
    "        else:\n",
    "            raise Exception('Reached end of chunk')\n",
    "    \n",
    "        \n",
    "\n",
    "class CIPHAR10():\n",
    "    def __init__(self,test_filepath,train_filepaths):\n",
    "        self.test_data = self.load_data(test_filepath)\n",
    "        self.train_data = [self.load_data(chunk) for chunk in train_filepaths]\n",
    "        \n",
    "    def load_data(self,filepath):\n",
    "        return Chunk(filepath)\n",
    "\n",
    "train_filepaths = ['./data/cifar-10-batches-py/data_batch_{}'.format(i) for i in range(1,6)]\n",
    "test_filepaths = './data/cifar-10-batches-py/test_batch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We update our X placeholder to take in these 32x32x3 arrays. Y remains unchanged as there are still 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable(shape):\n",
    "    if type(shape) is not list:\n",
    "        shape = [shape]\n",
    "    return tf.Variable(tf.random_normal(shape))\n",
    "\n",
    "def conv2dlayer(x, filt, s=2):\n",
    "    b = filt[-1]\n",
    "    filt = variable(filt)\n",
    "    x = tf.nn.conv2d(x, filt, strides=[1,s,s,1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x,variable([b]))\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def max2dpool(x, k=2, s=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1,k,k,1], strides=[1,s,s,1], padding='SAME')\n",
    "\n",
    "def full_conn(x, hidden_size):\n",
    "    flat = np.prod(x.get_shape().as_list()[1:])\n",
    "    fc = tf.reshape(x, [-1, flat] )\n",
    "    fc = tf.matmul(fc, variable([flat,hidden_size]))\n",
    "    fc = tf.nn.bias_add(fc, variable([hidden_size]))\n",
    "    return tf.nn.relu(fc)\n",
    "    \n",
    "def pred_layer(x, n_classes):\n",
    "    y = tf.matmul(x, variable([x.get_shape().as_list()[-1],10]))\n",
    "    y = tf.nn.bias_add(y, variable(n_classes))\n",
    "    return y\n",
    "\n",
    "def lrn(x):\n",
    "    return tf.nn.lrn(x, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape = [None, 32, 32, 3])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, 10])\n",
    "\n",
    "conv1 = conv2dlayer(X, [5,5,3,32],s=1)\n",
    "pool1 = max2dpool(conv1, k=3, s=2)\n",
    "# lrn1 = lrn(pool1)\n",
    "conv2 = conv2dlayer(pool1, [5,5,32,64], s=1)\n",
    "pool2 = max2dpool(conv2, k=3, s=2)\n",
    "# lrn2 = lrn(pool2)\n",
    "fc1 = full_conn(pool2, 300)\n",
    "y = pred_layer(fc1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(y,Y))\n",
    "optimiser = tf.train.AdamOptimizer(0.0001).minimize(cost)\n",
    "results = tf.cast(tf.equal(tf.arg_max(y,1), tf.arg_max(Y,1)), tf.float32)\n",
    "count = tf.reduce_sum(results)\n",
    "accuracy = tf.reduce_mean(results)\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "batch_size = 10\n",
    "n_batches = 1000\n",
    "epochs = 10\n",
    "n_random_select = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on total test set: 26.77\n",
      "Accuracy on total test set: 30.94\n",
      "Accuracy on total test set: 33.89\n",
      "Accuracy on total test set: 35.23\n",
      "Accuracy on total test set: 36.65\n",
      "Accuracy on total test set: 38.13\n",
      "Accuracy on total test set: 39.39\n",
      "Accuracy on total test set: 40.12\n",
      "Accuracy on total test set: 40.9\n",
      "Accuracy on total test set: 41.4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    ciphar10 = CIPHAR10(test_filepaths,train_filepaths)\n",
    "    for ep in range(epochs):\n",
    "        for chunk in ciphar10.train_data:\n",
    "            for b in range(n_batches):\n",
    "                b_images, b_labels = chunk.next_batch(batch_size)\n",
    "                _, c = sess.run([optimiser, cost], feed_dict={X:b_images, Y:b_labels})\n",
    "            chunk.idx = 0\n",
    "        \n",
    "#         if ep % 10 == 0:\n",
    "        total_count = 0\n",
    "        for i in range(1000):\n",
    "            t_batch = ciphar10.test_data.images[10*i:10*i + 10]\n",
    "            t_labels = ciphar10.test_data.labels[10*i:10*i + 10]\n",
    "            cnt, acc = sess.run([count,accuracy], feed_dict={X: t_batch, Y: t_labels})\n",
    "            total_count += cnt\n",
    "        print \"Accuracy on total test set: {}\".format(total_count/100)\n",
    "            \n",
    "\n",
    "#         if ep % 10 == 0:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We see that we only reach a maximum of around 40%. This is certainly a harder problem!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
